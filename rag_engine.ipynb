{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/arctic/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You try to use a model that was created with version 2.7.0.dev0, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n",
      "/opt/miniconda3/envs/arctic/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/arctic/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "import os\n",
    "import shutil\n",
    "model = HuggingFaceEmbeddings(model_name=\"snowflake/arctic-embed-l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 197 documents into 49471 chunks.\n",
      "without eating.\n",
      "And a very clever\n",
      "scientist decided\n",
      "to study why it is that certain\n",
      "animals like Gila monsters\n",
      "can go a long period of time\n",
      "without ingesting anything.\n",
      "And it's because they produce\n",
      "very large amounts of GLP-1.\n",
      "They isolate the\n",
      "peptide from GLP-1,\n",
      "then they looked for the\n",
      "analogous peptide in humans.\n",
      "And it turns out\n",
      "that does exist.\n",
      "And as I mentioned, it's\n",
      "released in both brain and body\n",
      "to make you feel full and sated.\n",
      "Why am I telling you all this?\n",
      "Well, today we're going\n",
      "to talk about caffeine.\n",
      "And there's one particular\n",
      "caffeine source,\n",
      "which is yerba mat√©, and there\n",
      "are some other forms of teas\n",
      "similar to yerba mate that\n",
      "stimulate the release of GLP-1\n",
      "significantly.\n",
      "There are also nowadays drugs\n",
      "which are called analogues\n",
      "of GLP-1.\n",
      "So these are drugs\n",
      "that mimic or are\n",
      "identical to the kind of\n",
      "GLP-1 that you would make.\n",
      "And those drugs are proven\n",
      "to be very effective\n",
      "for the treatment of\n",
      "certain forms of diabetes\n",
      "and for the\n",
      "treatment of obesity,\n",
      "but they trigger\n",
      "{'source': 'transcripts/Using Caffeine to Optimize Mental & Physical Performance | Huberman Lab Podcast 101.md', 'start_index': 5011}\n",
      "Saved 49471 chunks to chroma.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/arctic/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "CHROMA_PATH = \"chroma\"\n",
    "DATA_PATH = \"transcripts\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    generate_data_store()\n",
    "\n",
    "\n",
    "def generate_data_store():\n",
    "    documents = load_documents()\n",
    "    chunks = split_text(documents)\n",
    "    save_to_chroma(chunks)\n",
    "\n",
    "\n",
    "def load_documents():\n",
    "    loader = DirectoryLoader(DATA_PATH, glob=\"*.md\")\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "\n",
    "def split_text(documents: list[Document]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=500,\n",
    "        length_function=len,\n",
    "        add_start_index=True,\n",
    "    )\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
    "\n",
    "    document = chunks[10]\n",
    "    print(document.page_content)\n",
    "    print(document.metadata)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def save_to_chroma(chunks: list[Document]):\n",
    "    # Clear out the database first.\n",
    "    if os.path.exists(CHROMA_PATH):\n",
    "        shutil.rmtree(CHROMA_PATH)\n",
    "\n",
    "    # Create a new DB from the documents.\n",
    "    db = Chroma.from_documents(\n",
    "        chunks, model, persist_directory=CHROMA_PATH\n",
    "    )\n",
    "    db.persist()\n",
    "    print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "podquest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
